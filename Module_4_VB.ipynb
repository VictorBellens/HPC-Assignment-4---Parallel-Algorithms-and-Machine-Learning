{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "#Assignment Module 4.  Distributed Training with TensorFlow - Multi-GPU and Multi-Node Simulation\n",
    "\n",
    "###Problem Statement:\n",
    "You are tasked with implementing and optimizing a neural network for image classification using TensorFlow's distributed strategies. First, you will use the MirroredStrategy for distributed training across multiple GPUs (Colab simulates multi-GPU setups). Then, you'll extend the setup to a multi-node distributed system using MultiWorkerMirroredStrategy to simulate multi-node training.\n",
    "\n",
    "You will implement and optimize the training process and compare the performance between the multi-GPU and multi-node setups.\n",
    "\n",
    "###Part 1: Multi-GPU Training using MirroredStrategy\n",
    "1. Define a Distributed Strategy: Use tf.distribute.MirroredStrategy() to simulate multi-GPU training.\n",
    "\n",
    "2. Dataset: Use the MNIST dataset, ensuring it is preprocessed and normalized.\n",
    "\n",
    "3. Model: Build a simple CNN using TensorFlow’s Sequential API.\n",
    "\n",
    "4. Training: Train the model using the distributed strategy and compare the performance with non-distributed training.\n",
    "\n",
    "5. Evaluation: Evaluate the model on the test set and ensure that the training converges correctly with multiple GPUs.\n",
    "\n",
    "\n",
    "\n",
    "###Part 2: Multi-Node Training using MultiWorkerMirroredStrategy\n",
    "1. Simulate a Multi-Node Setup: Set up MultiWorkerMirroredStrategy with appropriate environment variables (TF_CONFIG) for node communication.\n",
    "\n",
    "2. Training: Train the same model across simulated nodes and compare the performance.\n",
    "\n",
    "3. Evaluation: Evaluate the model after training in the multi-node setup."
   ],
   "metadata": {
    "id": "jVnd-UaBtRWh"
   }
  },
  {
   "cell_type": "markdown",
   "source": "# Part 1",
   "metadata": {
    "id": "PUEicgrft1gp"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yaqrUO5OlzpF",
    "outputId": "db529b90-2567-4516-dba0-8b2a3fc832c1",
    "ExecuteTime": {
     "end_time": "2024-11-09T17:09:42.466267Z",
     "start_time": "2024-11-09T17:09:42.040461Z"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "import time"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T17:11:06.855463Z",
     "start_time": "2024-11-09T17:10:20.319254Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Use MirroredStrategy for multi-GPU training\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print(\"Number of devices in strategy:\", strategy.num_replicas_in_sync)\n",
    "\n",
    "# Load the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Reshape and normalize the images\n",
    "x_train = x_train.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
    "x_test = x_test.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
    "batch_sizes = [64, 128, 256]\n",
    "\n",
    "\n",
    "def create_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "\n",
    "# Batch Sizes to Experiment\n",
    "# Train and Evaluate the Model without using MirroredStrategy\n",
    "\n",
    "\n",
    "print(\"\\nTraining on Single GPU:\")\n",
    "for batch_size in batch_sizes:\n",
    "    print(f\"\\nBatch Size: {batch_size}\")\n",
    "    #  a new model instance\n",
    "    model_single_gpu = create_model()\n",
    "    model_single_gpu.compile(optimizer='adam',\n",
    "                             loss='sparse_categorical_crossentropy',\n",
    "                             metrics=['accuracy'])\n",
    "    # training time\n",
    "    start_time = time.time()\n",
    "    model_single_gpu.fit(x_train, y_train, epochs=5, batch_size=batch_size, verbose=2)\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "    print(f\"Training Time: {training_time:.2f} seconds\")\n",
    "    # eval the model\n",
    "    test_loss, test_acc = model_single_gpu.evaluate(x_test, y_test, verbose=2)\n",
    "    print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "Number of devices in strategy: 1\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001B[1m11490434/11490434\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 0us/step\n",
      "\n",
      "Training on Single GPU:\n",
      "\n",
      "Batch Size: 64\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vicbe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 - 3s - 4ms/step - accuracy: 0.9525 - loss: 0.1607\n",
      "Epoch 2/5\n",
      "938/938 - 3s - 3ms/step - accuracy: 0.9851 - loss: 0.0476\n",
      "Epoch 3/5\n",
      "938/938 - 3s - 3ms/step - accuracy: 0.9896 - loss: 0.0331\n",
      "Epoch 4/5\n",
      "938/938 - 3s - 4ms/step - accuracy: 0.9925 - loss: 0.0243\n",
      "Epoch 5/5\n",
      "938/938 - 3s - 3ms/step - accuracy: 0.9936 - loss: 0.0196\n",
      "Training Time: 16.03 seconds\n",
      "313/313 - 0s - 1ms/step - accuracy: 0.9909 - loss: 0.0281\n",
      "Test Accuracy: 0.9909\n",
      "\n",
      "Batch Size: 128\n",
      "Epoch 1/5\n",
      "469/469 - 3s - 7ms/step - accuracy: 0.9389 - loss: 0.2059\n",
      "Epoch 2/5\n",
      "469/469 - 3s - 6ms/step - accuracy: 0.9823 - loss: 0.0580\n",
      "Epoch 3/5\n",
      "469/469 - 3s - 5ms/step - accuracy: 0.9878 - loss: 0.0397\n",
      "Epoch 4/5\n",
      "469/469 - 2s - 5ms/step - accuracy: 0.9906 - loss: 0.0308\n",
      "Epoch 5/5\n",
      "469/469 - 2s - 5ms/step - accuracy: 0.9923 - loss: 0.0243\n",
      "Training Time: 13.37 seconds\n",
      "313/313 - 0s - 1ms/step - accuracy: 0.9899 - loss: 0.0292\n",
      "Test Accuracy: 0.9899\n",
      "\n",
      "Batch Size: 256\n",
      "Epoch 1/5\n",
      "235/235 - 3s - 14ms/step - accuracy: 0.9203 - loss: 0.2842\n",
      "Epoch 2/5\n",
      "235/235 - 3s - 12ms/step - accuracy: 0.9788 - loss: 0.0689\n",
      "Epoch 3/5\n",
      "235/235 - 3s - 12ms/step - accuracy: 0.9854 - loss: 0.0479\n",
      "Epoch 4/5\n",
      "235/235 - 3s - 12ms/step - accuracy: 0.9883 - loss: 0.0375\n",
      "Epoch 5/5\n",
      "235/235 - 3s - 12ms/step - accuracy: 0.9907 - loss: 0.0306\n",
      "Training Time: 14.52 seconds\n",
      "313/313 - 0s - 1ms/step - accuracy: 0.9891 - loss: 0.0337\n",
      "Test Accuracy: 0.9891\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T17:12:47.122395Z",
     "start_time": "2024-11-09T17:11:57.635485Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train and Evaluate the Model Using MirroredStrategy\n",
    "\n",
    "print(\"\\nTraining with MirroredStrategy:\")\n",
    "for batch_size in batch_sizes:\n",
    "    print(f\"\\nBatch Size: {batch_size}\")\n",
    "    with strategy.scope():\n",
    "        # A new model instance\n",
    "        model_multi_gpu = create_model()\n",
    "        model_multi_gpu.compile(optimizer='adam',\n",
    "                                loss='sparse_categorical_crossentropy',\n",
    "                                metrics=['accuracy'])\n",
    "    #  training time\n",
    "    start_time = time.time()\n",
    "    model_multi_gpu.fit(x_train, y_train, epochs=5, batch_size=batch_size, verbose=2)\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "    print(f\"Training Time: {training_time:.2f} seconds\")\n",
    "    # eval the model\n",
    "    test_loss, test_acc = model_multi_gpu.evaluate(x_test, y_test, verbose=2)\n",
    "    print(f\"Test Accuracy: {test_acc:.4f}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with MirroredStrategy:\n",
      "\n",
      "Batch Size: 64\n",
      "WARNING:tensorflow:From C:\\Users\\vicbe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:204: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "Epoch 1/5\n",
      "938/938 - 4s - 4ms/step - accuracy: 0.9502 - loss: 0.1636\n",
      "Epoch 2/5\n",
      "938/938 - 3s - 4ms/step - accuracy: 0.9852 - loss: 0.0471\n",
      "Epoch 3/5\n",
      "938/938 - 3s - 4ms/step - accuracy: 0.9895 - loss: 0.0331\n",
      "Epoch 4/5\n",
      "938/938 - 3s - 3ms/step - accuracy: 0.9927 - loss: 0.0239\n",
      "Epoch 5/5\n",
      "938/938 - 3s - 3ms/step - accuracy: 0.9940 - loss: 0.0196\n",
      "Training Time: 16.90 seconds\n",
      "313/313 - 0s - 1ms/step - accuracy: 0.9915 - loss: 0.0278\n",
      "Test Accuracy: 0.9915\n",
      "\n",
      "Batch Size: 128\n",
      "Epoch 1/5\n",
      "469/469 - 3s - 7ms/step - accuracy: 0.9437 - loss: 0.2011\n",
      "Epoch 2/5\n",
      "469/469 - 3s - 6ms/step - accuracy: 0.9827 - loss: 0.0553\n",
      "Epoch 3/5\n",
      "469/469 - 3s - 6ms/step - accuracy: 0.9883 - loss: 0.0386\n",
      "Epoch 4/5\n",
      "469/469 - 3s - 6ms/step - accuracy: 0.9909 - loss: 0.0294\n",
      "Epoch 5/5\n",
      "469/469 - 3s - 6ms/step - accuracy: 0.9932 - loss: 0.0224\n",
      "Training Time: 14.87 seconds\n",
      "313/313 - 0s - 1ms/step - accuracy: 0.9900 - loss: 0.0283\n",
      "Test Accuracy: 0.9900\n",
      "\n",
      "Batch Size: 256\n",
      "Epoch 1/5\n",
      "235/235 - 3s - 14ms/step - accuracy: 0.9209 - loss: 0.2762\n",
      "Epoch 2/5\n",
      "235/235 - 3s - 13ms/step - accuracy: 0.9791 - loss: 0.0680\n",
      "Epoch 3/5\n",
      "235/235 - 3s - 13ms/step - accuracy: 0.9855 - loss: 0.0495\n",
      "Epoch 4/5\n",
      "235/235 - 3s - 13ms/step - accuracy: 0.9881 - loss: 0.0383\n",
      "Epoch 5/5\n",
      "235/235 - 3s - 14ms/step - accuracy: 0.9911 - loss: 0.0307\n",
      "Training Time: 16.10 seconds\n",
      "313/313 - 0s - 2ms/step - accuracy: 0.9895 - loss: 0.0329\n",
      "Test Accuracy: 0.9895\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "# Part 2"
   ],
   "metadata": {
    "id": "41GcXJhtt-Eo"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# importing libs\n",
    "import os\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "# remove TF_CONFIG if it was set\n",
    "os.environ.pop('TF_CONFIG', None)\n",
    "\n",
    "# define the strategy\n",
    "strategy = tf.distribute.MultiWorkerMirroredStrategy()\n",
    "print(\"Number of devices in strategy:\", strategy.num_replicas_in_sync)"
   ],
   "metadata": {
    "id": "i025SoeVuB2T",
    "ExecuteTime": {
     "end_time": "2024-11-09T17:19:55.314457Z",
     "start_time": "2024-11-09T17:19:55.309653Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/device:CPU:0',)\n",
      "INFO:tensorflow:Single-worker MultiWorkerMirroredStrategy with local_devices = ('/device:CPU:0',), communication = CommunicationImplementation.AUTO\n",
      "Number of devices in strategy: 1\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T17:21:02.096256Z",
     "start_time": "2024-11-09T17:20:40.632773Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# load and preprocess the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "#  reshape and normalize the images\n",
    "x_train = x_train.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
    "x_test = x_test.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
    "\n",
    "#  the datasets\n",
    "GLOBAL_BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 10000\n",
    "EPOCHS = 5\n",
    "\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(GLOBAL_BATCH_SIZE)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "test_dataset = test_dataset.batch(GLOBAL_BATCH_SIZE)\n",
    "\n",
    "# distribute the datasets\n",
    "train_dist_dataset = strategy.experimental_distribute_dataset(train_dataset)\n",
    "test_dist_dataset = strategy.experimental_distribute_dataset(test_dataset)\n",
    "\n",
    "def create_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "with strategy.scope():\n",
    "\n",
    "    model = create_model()\n",
    "    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        reduction=tf.keras.losses.Reduction.NONE)\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "    train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "    train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "    test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "    test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n",
    "    \n",
    "    \n",
    "\n",
    "def compute_loss(labels, predictions):\n",
    "    per_example_loss = loss_object(labels, predictions)\n",
    "    return tf.nn.compute_average_loss(per_example_loss, global_batch_size=GLOBAL_BATCH_SIZE)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step(inputs):\n",
    "    images, labels = inputs\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(images, training=True)\n",
    "        loss = compute_loss(labels, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    train_loss.update_state(loss)\n",
    "    train_accuracy.update_state(labels, predictions)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def test_step(inputs):\n",
    "    images, labels = inputs\n",
    "    predictions = model(images, training=False)\n",
    "    loss = compute_loss(labels, predictions)\n",
    "\n",
    "    test_loss.update_state(loss)\n",
    "    test_accuracy.update_state(labels, predictions)\n",
    "    \n",
    "for epoch in range(EPOCHS):\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss.reset_state()\n",
    "    train_accuracy.reset_state()\n",
    "    test_loss.reset_state()\n",
    "    test_accuracy.reset_state()\n",
    "\n",
    "    for inputs in train_dist_dataset:\n",
    "        strategy.run(train_step, args=(inputs,))\n",
    "\n",
    "    for inputs in test_dist_dataset:\n",
    "        strategy.run(test_step, args=(inputs,))\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    template = ('Epoch {}, Loss: {:.4f}, Accuracy: {:.4f}, '\n",
    "                'Test Loss: {:.4f}, Test Accuracy: {:.4f}, Time: {:.2f} sec')\n",
    "    print(template.format(epoch + 1,\n",
    "                          train_loss.result(),\n",
    "                          train_accuracy.result(),\n",
    "                          test_loss.result(),\n",
    "                          test_accuracy.result(),\n",
    "                          end_time - start_time))\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.1706, Accuracy: 0.9488, Test Loss: 0.0478, Test Accuracy: 0.9847, Time: 4.83 sec\n",
      "Epoch 2, Loss: 0.0484, Accuracy: 0.9850, Test Loss: 0.0333, Test Accuracy: 0.9883, Time: 4.04 sec\n",
      "Epoch 3, Loss: 0.0343, Accuracy: 0.9894, Test Loss: 0.0373, Test Accuracy: 0.9878, Time: 4.02 sec\n",
      "Epoch 4, Loss: 0.0252, Accuracy: 0.9923, Test Loss: 0.0301, Test Accuracy: 0.9900, Time: 3.99 sec\n",
      "Epoch 5, Loss: 0.0198, Accuracy: 0.9936, Test Loss: 0.0322, Test Accuracy: 0.9887, Time: 4.31 sec\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": "",
   "metadata": {
    "id": "H4040E-juGHp"
   }
  },
  {
   "cell_type": "markdown",
   "source": "",
   "metadata": {
    "id": "xcUwDyvC1bap"
   }
  },
  {
   "cell_type": "markdown",
   "source": "",
   "metadata": {
    "id": "rH1FghaRx3nu"
   }
  }
 ]
}
